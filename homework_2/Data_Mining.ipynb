{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T14:51:26.614240Z",
     "start_time": "2018-01-23T14:51:24.562806Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T14:51:26.690475Z",
     "start_time": "2018-01-23T14:51:26.616296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data of BFRSS about Crude Prevalence \n",
    "typeOfTarget = 'CP'\n",
    "data =  pd.read_csv(\"Datasets/Diabetes_\"+typeOfTarget+\"_allYear_overall.csv\",sep = ';',encoding = \"utf-8-sig\")\n",
    "# Clean data an format the name of the columns\n",
    "mylist = ['All States and DC (median) **', 'All States, DC and Territories (median) **', 'Guam', \n",
    "        'Puerto Rico', 'Virgin Islands']\n",
    "data.rename(columns = {'Locationdesc': 'State',\n",
    "                     'Confidence_limit_Low':'Lower_CI',\n",
    "                     'Confidence_limit_High':'Upper_CI',\n",
    "                     },inplace = True)\n",
    "data = data[~data.State.isin(mylist)].reset_index(drop = True)\n",
    "# Change the type of years in string for multiIndex\n",
    "data.Year = data.Year.astype(str)\n",
    "# Reorder columns\n",
    "data = data[[\"State\",\"Year\",\"Data_value\",'Lower_CI','Upper_CI','Sample_Size']]\n",
    "#data.to_csv('Crude_prevalence_diabetes_BFRSS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T14:51:26.745592Z",
     "start_time": "2018-01-23T14:51:26.692447Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data of BFRSS about Age-Adjusted Prevalence \n",
    "typeOfTarget = 'APP'\n",
    "data =  pd.read_csv(\"Datasets/Diabetes_\"+typeOfTarget+\"_allYear_overall.csv\",sep = ';',encoding = \"utf-8-sig\")\n",
    "# Clean data an format the name of the columns\n",
    "mylist = ['All States and DC (median) **', 'All States, DC and Territories (median) **', 'Guam', \n",
    "        'Puerto Rico', 'Virgin Islands']\n",
    "# Add by hand Rhode Island for the years 2011 and 2012\n",
    "data.rename(columns = {'Locationdesc': 'State',\n",
    "                     'Low_Confidence_Limit':'Lower_CI',\n",
    "                      'High_Confidence_Limit':'Upper_CI'\n",
    "                      },inplace = True)\n",
    "data = data[~data.State.isin(mylist)].reset_index(drop = True)\n",
    "# Change the type of years in string for multiIndex\n",
    "data.Year = data.Year.astype(str)\n",
    "# Reorder columns\n",
    "data = data[[\"State\",\"Year\",\"Data_value\",'Lower_CI','Upper_CI','Sample_Size']]\n",
    "#data.to_csv('AgeAdjusted_prevalence_diabetes_BFRSS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T14:51:44.096916Z",
     "start_time": "2018-01-23T14:51:26.748317Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq\n",
    "# Unofficial Google Trends API for download the keywords\n",
    "pytrend  =  TrendReq()\n",
    "kws = [['Corticosteroids ', 'Obstructive sleep apnea ','Blood glucose ','Glucose levels','Hyperglycemia'],\n",
    "    ['2diabetes','Type2','diabetes','Hypertension','Diabetesin','Type2'],\n",
    "    ['Insulin','Glucose','HeartDisease','Cholesterol','Diabetes']]\n",
    "\n",
    "for kw in kws:\n",
    "    for t in range(2004,2017):\n",
    "        # Create payload and capture API tokens. Only needed for interest_over_time(), interest_by_region() & related_queries()\n",
    "        pytrend.build_payload(kw_list  =  kw, \n",
    "                              cat  =  45, \n",
    "                              timeframe  =  str(t)+'-01-01'+' '+str(t)+'-12-31', \n",
    "                              geo = 'US', \n",
    "                              gprop = '')\n",
    "\n",
    "        # Interest by Region\n",
    "        interest_by_region_df  =  pytrend.interest_by_region()\n",
    "        name = \"\".join([word.replace(\" \",\"\") for word in kw])\n",
    "        #interest_by_region_df.to_csv(name+'_'+str(t)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T14:52:31.707695Z",
     "start_time": "2018-01-23T14:52:22.326689Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emmanuele\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Emmanuele\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Read data of google trends and takes keyword\n",
    "per = ['gt/InsulinGlucoseHeartDiseaseCholesterolDiabetes_',\n",
    "      'gt/2diabetesType2diabetesHypertensionDiabetesinType2_',\n",
    "    'gt/CorticosteroidsObstructivesleepapneaBloodglucoseGlucoselevelsHyperglycemia_']\n",
    "\n",
    "#define the start year for Crude Prevalence\n",
    "start_year = 2004\n",
    "data =  pd.read_csv(\"Datasets/Crude_prevalence_diabetes_BFRSS.csv\",sep = ',',encoding = \"utf-8-sig\",index_col = 0)\n",
    "# Take states\n",
    "states = sorted( list( set( data.State)))\n",
    "# Take year\n",
    "years = list(range(start_year,2017))\n",
    "#Union of BRFSS data Crude Prevalence & google trends in a single dataset with primary key the tuple (State,year) \n",
    "df_gt,keywords = gt_dataset(per,states,start_year)\n",
    "df = data[[\"State\",\"Year\"]]\n",
    "for kw in keywords:\n",
    "    col = np.array(())\n",
    "    for y in reversed(years):\n",
    "        col = np.concatenate( ( col,df_gt[(str(kw) +':'+ str(y))].values )) \n",
    "    df[kw] = col\n",
    "df[\"y\"] =  data.loc[:,\"Data_value\"]\n",
    "#df.to_csv('Crude_prevalence_diabetes_BFRSS_union_GT.csv')\n",
    "\n",
    "#define the start year for Age-Adjusted Prevalence\n",
    "start_year = 2011\n",
    "data =  pd.read_csv(\"Datasets/AgeAdjusted_prevalence_diabetes_BFRSS.csv\",sep = ',',encoding = \"utf-8-sig\",index_col = 0)\n",
    "# Take states\n",
    "states = sorted( list( set( data.State)))\n",
    "# Take year\n",
    "years = list(range(start_year,2017))\n",
    "# Union of BRFSS data Crude Prevalence & google trends in a single dataset with primary key the tuple (State,year)\n",
    "df_gt,keywords = gt_dataset(per,states,start_year)\n",
    "df = data[[\"State\",\"Year\"]]\n",
    "for kw in keywords:\n",
    "    col = np.array(())\n",
    "    for y in reversed(years):\n",
    "        col = np.concatenate( ( col,df_gt[(str(kw) +':'+ str(y))].values )) \n",
    "    df[kw] = col\n",
    "df[\"y\"] =  data.loc[:,\"Data_value\"]\n",
    "#df.to_csv('AgeAdjusted_prevalence_diabetes_BFRSS_union_GT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T14:52:35.038910Z",
     "start_time": "2018-01-23T14:52:35.020833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataset that contain info about the target value (Crude Prevalence) like CI and sample size\n",
    "start_year = 2004\n",
    "data =  pd.read_csv(\"Datasets/Crude_prevalence_diabetes_BFRSS.csv\",sep = ',',encoding = \"utf-8-sig\",index_col = 0)\n",
    "df_info = data[[\"State\",\"Year\",'Lower_CI','Upper_CI', 'Sample_Size']]\n",
    "#df_info.to_csv('Crude_prevalence_INFO_diabetes_BFRSS_union_GT.csv')\n",
    "\n",
    "# Create a dataset that contain info about the target value (Age-Adjusted Prevalence) like CI and sample size\n",
    "start_year = 2011\n",
    "data =  pd.read_csv(\"Datasets/AgeAdjusted_prevalence_diabetes_BFRSS.csv\",sep = ',',encoding = \"utf-8-sig\",index_col = 0)\n",
    "df_info = data[[\"State\",\"Year\",'Lower_CI','Upper_CI', 'Sample_Size']]\n",
    "#df_info.to_csv('AgeAdjusted_prevalence_INFO_diabetes_BFRSS_union_GT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T14:52:37.665677Z",
     "start_time": "2018-01-23T14:52:37.648594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataset about Income from 2004 to 2016\n",
    "df_income =  pd.read_csv(\"Datasets/Income_CP_allYear_lessthan15000.csv\",sep = ';',encoding = \"utf-8-sig\")\n",
    "# Clean data an format the name of the columns\n",
    "df_income.rename(columns = {'Locationdesc': 'State',\n",
    "                      'Data_value' : 'IncomePercent'},inplace = True)\n",
    "mylist = ['Guam','Puerto Rico', 'Virgin Islands']\n",
    "# Add by hand Hawaii in 2004\n",
    "df_income = df_income[['Year','State','IncomePercent']]\n",
    "df_income = df_income[~df_income.State.isin(mylist)].reset_index(drop = True)\n",
    "#df_income.to_csv(\"Income_2004_2016_AllStates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T14:52:43.834426Z",
     "start_time": "2018-01-23T14:52:43.720864Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataset about Poverty from 2004 to 2016\n",
    "table  =  pd.read_csv('Datasets/Poverty_allYear.csv', sep = ';',encoding = 'UTF-8-sig ')\n",
    "# Clean data an format the name of the columns\n",
    "mylist = ['STATE','2004 (14)','2005','2006','2007','2008','2009','2010 (17)','2011','2012','2013 (18)','2013 (19)','2014','2015']\n",
    "table = table[~table.STATE.isin(mylist)].reset_index()\n",
    "table = table[['STATE','Percent']]\n",
    "l = []\n",
    "for year in reversed(range(2004,2017)):\n",
    "    l.extend(np.repeat(str(year),51).tolist())\n",
    "table.rename(columns = {'STATE': 'State' , 'Percent' : 'PovertyPercent' },inplace = True)\n",
    "table['Year'] = l\n",
    "table = table[['State','Year','PovertyPercent']] # Change the order\n",
    "table.State = table.State.replace(\"D.C.\",\"District of Columbia\",regex = True)\n",
    "table.PovertyPercent = table.PovertyPercent.replace(\",\",\".\",regex = True).astype(float)\n",
    "#table.to_csv('Poverty_2004_2016_AllStates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-23T14:52:47.818791Z",
     "start_time": "2018-01-23T14:52:47.727419Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Datasets/insurance_2004_2012.csv',header = 2,encoding = 'utf-8-sig',sep = ';')\n",
    "# Clean data an format the name of the columns\n",
    "states = [i.replace(\":\",\"\") for i in df['Unnamed: 0'].unique()[15:].tolist()]\n",
    "insurance_list = []\n",
    "year_list = []\n",
    "for i in reversed(range(2004,2013)):\n",
    "    insurance_list.extend(df[df['Unnamed: 0'] == str(i)]['Percent.1'].values.tolist()[1:]) \n",
    "    year_list.extend(np.repeat(i,51))\n",
    "\n",
    "insurance_dict  =  {'Year': year_list,\n",
    "                  'InsurancePercent': insurance_list,\n",
    "                  'State':states*9}\n",
    "insurance_df  =  pd.DataFrame.from_dict(insurance_dict)\n",
    "insurance_df = insurance_df[['Year','State','InsurancePercent']]\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('Datasets/insurance_2013_2016.csv')\n",
    "df1[df1.columns[1:]] = 100-df1[df1.columns[1:]]\n",
    "insurance_df2 = pd.DataFrame()\n",
    "for i in reversed(range(2013,2017)):\n",
    "    d = { \"Year\" :np.repeat(i,51) , \"State\" : states , \"InsurancePercent\" : df1[str(i)].values}   \n",
    "    df_col = pd.DataFrame(d)\n",
    "    insurance_df2  =  pd.concat([insurance_df2,df_col],axis = 0)\n",
    "insurance_df2 = insurance_df2[['Year','State','InsurancePercent']]\n",
    "\n",
    "\n",
    "df_insurance_complete = pd.concat([insurance_df2,insurance_df],axis = 0)\n",
    "df_insurance_complete.InsurancePercent = df_insurance_complete.InsurancePercent.replace(\",\",\".\",regex = True).astype(float)\n",
    "#df_insurance_complete.to_csv('Insurance_2004_2016_AllStates.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
